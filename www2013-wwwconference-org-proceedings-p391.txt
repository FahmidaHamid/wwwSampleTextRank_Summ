 first, we built a dataset consisting of 28 million pairs of (query,question), in which the question originated from yahoo! answers, keeping only the title as the question s text. we retained only pairs in which all query terms appear in the question, as an easy approximation of ensuring relevance to the query. we  rst describe how question candidates are generated for a given query. to rank the different question candidates, for both completing our baseline step as well as conducting our reranking, we transform each question into a feature vector. this feature re ects the grammatical correctness of the question. question pos language models. we tag the query words with pos by copying the tags that were assigned to the query words in the question, which was built as an instantiated template. given the k question candidates for the query in the training pair, if the target question is not found among them, the current pair is skipped. for each query we collected the top three question suggestions as ranked by the baseline and the reranking steps. model query we also marked each question as  diverse  if it was not redundant with a higher ranked question. besides question generation from queries, other question generation tasks were addressed in the literature.