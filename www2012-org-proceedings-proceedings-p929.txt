 in these methods data points (objects) are represented as bit vectors, and such a representation helps in  nding the neighbors quickly2.  query and the document are two distinct types of inputs, but we do not consider it here. after learning, the bit vector representation is used to  nd nearest neighbors for a query vector within a set of documents. the query bit vector is then compared against the document bit vectors in the search set with hamming distance as the metric. it takes a query and a document as inputs and computes a scalar score with which the document can be ranked. let bq   {0, 1}b be the bit vector for the query and bi   {0, 1}b be the bit vector for the ith document. score function for classi cation: for nearest neighbor classi cation, we do not break ties. given a test case, its bit vector is compared against the bit vectors for all the training cases. given a query, its bit vector is compared against the bit vectors for all the documents in the search set. we compare against other methods that compute a bit vector representation.